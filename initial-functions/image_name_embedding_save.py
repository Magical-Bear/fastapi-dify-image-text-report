from dotenv import load_dotenv
load_dotenv("../.env")
import os
import json
import numpy as np
import jieba
from tqdm import tqdm
from openai import OpenAI


class ImageSemanticSearcher:
    """
    åŸºäºé˜¿é‡Œäº‘ DashScope embedding çš„å›¾ç‰‡è¯­ä¹‰æ£€ç´¢å™¨
    æ”¯æŒæœ¬åœ°ç¼“å­˜ embeddingï¼Œæå‡æ€§èƒ½
    """

    def __init__(self, image_dir, cache_path="../assets/embeddings/image_embeddings.json",
                 api_key_env="DASHSCOPE_API_KEY",
                 base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                 model="text-embedding-v4",
                 dimensions=1024):
        """
        åˆå§‹åŒ–
        :param image_dir: å›¾ç‰‡ç›®å½•
        :param cache_path: æœ¬åœ°embeddingç¼“å­˜è·¯å¾„
        :param api_key_env: ç¯å¢ƒå˜é‡å
        :param base_url: é˜¿é‡Œäº‘å…¼å®¹OpenAIæ¥å£URL
        :param model: embeddingæ¨¡å‹
        :param dimensions: å‘é‡ç»´åº¦
        """
        self.image_dir = image_dir
        self.cache_path = cache_path
        self.client = OpenAI(api_key=os.getenv(api_key_env), base_url=base_url)
        self.model = model
        self.dimensions = dimensions

        self.image_texts = []
        self.image_paths = []
        self.embeddings = None

        # 1ï¸âƒ£ åŠ è½½ç¼“å­˜æˆ–åˆå§‹åŒ–
        self._load_or_generate_embeddings()

    def _generate_embedding(self, text):
        """
        è°ƒç”¨ API è·å– embedding å‘é‡
        """
        resp = self.client.embeddings.create(
            model=self.model,
            input=[text],
            dimensions=self.dimensions
        )
        return resp.data[0].embedding

    def _load_or_generate_embeddings(self):
        """
        åŠ è½½ç¼“å­˜ï¼Œå¦‚æœæœ‰æ–°å›¾ç‰‡åˆ™å¢é‡ç”Ÿæˆ
        """
        print("ğŸ“‚ æ­£åœ¨åŠ è½½å›¾ç‰‡è¯­ä¹‰ä¸embedding...")
        embeddings_dict = {}

        # å°è¯•åŠ è½½ç¼“å­˜
        if os.path.exists(self.cache_path):
            with open(self.cache_path, "r", encoding="utf-8") as f:
                embeddings_dict = json.load(f)
            print(f"âœ… å·²åŠ è½½ç¼“å­˜ embedding ({len(embeddings_dict)} æ¡)ã€‚")

        # é€ä¸ªæ–‡ä»¶æ£€æŸ¥
        updated = False
        for file in tqdm(os.listdir(self.image_dir)):
            if not file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp')):
                continue

            img_path = os.path.join(self.image_dir, file)
            img_name = os.path.splitext(file)[0]
            seg_text = " ".join(jieba.lcut(img_name))

            self.image_paths.append(img_path)
            self.image_texts.append(seg_text)

            if img_path not in embeddings_dict:
                embedding = self._generate_embedding(seg_text)
                embeddings_dict[img_path] = embedding
                updated = True

        # å¦‚æœæœ‰æ–°æ•°æ®ï¼Œæ›´æ–°ç¼“å­˜
        if updated:
            with open(self.cache_path, "w", encoding="utf-8") as f:
                json.dump(embeddings_dict, f, ensure_ascii=False, indent=2)
            print("ğŸ’¾ å·²æ›´æ–°ç¼“å­˜æ–‡ä»¶ã€‚")

        # è½¬æ¢ä¸ºçŸ©é˜µ
        self.embeddings = np.array(list(embeddings_dict.values()), dtype=np.float32)
        self.image_paths = list(embeddings_dict.keys())

        # å½’ä¸€åŒ–ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦æ›´å¿«ï¼‰
        self.embeddings = self.embeddings / np.linalg.norm(self.embeddings, axis=1, keepdims=True)
        print(f"âœ… å·²åŠ è½½ {len(self.image_paths)} å¼ å›¾ç‰‡çš„ embeddingã€‚")

    def search(self, query_texts, top_k=3):
        """
        æœç´¢æœ€ç›¸ä¼¼çš„å›¾ç‰‡
        :param query_texts: list[str] æŸ¥è¯¢å¥å­ï¼ˆå¯ä»¥æ˜¯æ”¹å†™çš„å¤šä¸ªç‰ˆæœ¬ï¼‰
        :param top_k: è¿”å›å‰kä¸ªç»“æœ
        """
        if isinstance(query_texts, str):
            query_texts = [query_texts]

        # åˆå¹¶å¤šä¸ªæ”¹å†™çš„embeddingå–å¹³å‡ï¼ˆæå‡é²æ£’æ€§ï¼‰
        query_embeddings = []
        for text in query_texts:
            seg_text = " ".join(jieba.lcut(text))
            emb = np.array(self._generate_embedding(seg_text), dtype=np.float32)
            emb /= np.linalg.norm(emb)
            query_embeddings.append(emb)

        query_vec = np.mean(query_embeddings, axis=0)

        # æœ¬åœ°è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        scores = np.dot(self.embeddings, query_vec)

        top_indices = np.argsort(scores)[::-1][:top_k]
        results = [(self.image_paths[i], float(scores[i])) for i in top_indices]
        return results



if __name__ == '__main__':
    searcher = ImageSemanticSearcher("../assets/static_images")
    query_rewrites = [
        "GSMRå‘¼å«",
        "ä¸è½¦ç«™è”ç³»å¤±è´¥"
    ]

    results = searcher.search(query_rewrites, top_k=3)
    print(results)